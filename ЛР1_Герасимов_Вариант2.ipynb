{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bri_pAriNFqN"
      },
      "source": [
        "**Цель работы:**\n",
        "\n",
        "Осуществить предварительную обработку данных csv-файла, выявить и устранить проблемы в этих данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_e-GeJmgZ8l"
      },
      "source": [
        "# Загрузка набора данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeq9ZAbSguQS"
      },
      "source": [
        "### Описание предметной области"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHbH8zNIg0Ib"
      },
      "source": [
        "Вариант № 2\n",
        "\n",
        "Набор данных: drivers.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwin9ia7hT1i"
      },
      "source": [
        "### 1.Чтение файла (набора данных)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a5dYQO5YhOYa"
      },
      "outputs": [],
      "source": [
        "# импорт библиотек, чтение файла с помощью pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "df = pd.read_csv('drivers.csv', delimiter=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p82p53SvhjLN"
      },
      "source": [
        "### 2. Обзор данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAYzXaLrh-qh"
      },
      "source": [
        "2.1 Вывод первых 20 строк с помощью метода head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7yMo3VZ_hotx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          START_DATE          END_DATE CATEGORY*        START           STOP  \\\n",
            "0   01.10.2016 19:12  01.10.2016 19:32  Business      Midtown    East Harlem   \n",
            "1   01.11.2016 13:32  01.11.2016 13:46  Business      Midtown   Midtown East   \n",
            "2   01.12.2016 12:33  01.12.2016 12:49  Business      Midtown  Hudson Square   \n",
            "3    1.13.2016 15:00   1.13.2016 15:28  Business      Gulfton       Downtown   \n",
            "4    1.29.2016 21:21   1.29.2016 21:40  Business         Apex           Cary   \n",
            "5    1.30.2016 18:09   1.30.2016 18:24  Business         Apex           Cary   \n",
            "6   02.01.2016 12:10  02.01.2016 12:43  Business  Chapel Hill           Cary   \n",
            "7    02.04.2016 9:37  02.04.2016 10:09  Business  Morrisville           Cary   \n",
            "8   02.07.2016 18:03  02.07.2016 18:17  Business         Apex           Cary   \n",
            "9   02.07.2016 20:22  02.07.2016 20:40  Business  Morrisville           Cary   \n",
            "10  02.09.2016 20:24  02.09.2016 20:40  Business  Morrisville           Cary   \n",
            "11  02.11.2016 20:36  02.11.2016 20:51  Business  Morrisville           Cary   \n",
            "12  02.12.2016 11:14  02.12.2016 11:35  Business  Morrisville        Raleigh   \n",
            "13  02.12.2016 15:33  02.12.2016 16:06  Business  Morrisville           Cary   \n",
            "14   2.14.2016 14:46   2.14.2016 15:03  Business      Midtown   Midtown West   \n",
            "15   2.16.2016 10:31   2.16.2016 10:41  BUSINESS      Colombo        Colombo   \n",
            "16   2.16.2016 11:32   2.16.2016 12:02  Business      Colombo        Colombo   \n",
            "17   2.16.2016 12:39   2.16.2016 12:42  Business      Colombo        Colombo   \n",
            "18   2.16.2016 13:43   2.16.2016 13:55  BUSINESS      Colombo        Colombo   \n",
            "19   2.16.2016 16:34   2.16.2016 17:10  Business      Colombo        Colombo   \n",
            "\n",
            "      MILES    PURPOSEroute  \n",
            "0   44963.0         MEETING  \n",
            "1   45108.0  Meal/Entertain  \n",
            "2   45170.0  Meal/Entertain  \n",
            "3   45149.0         Meeting  \n",
            "4   45051.0  Meal/Entertain  \n",
            "5   45112.0  Customer Visit  \n",
            "6   45008.0  Customer Visit  \n",
            "7   45116.0  Meal/Entertain  \n",
            "8   45112.0  Customer Visit  \n",
            "9   44932.0         Meeting  \n",
            "10  44932.0  Meal/Entertain  \n",
            "11  44932.0  Temporary Site  \n",
            "12     17.0  Customer Visit  \n",
            "13  45057.0  Customer Visit  \n",
            "14      2.0         Meeting  \n",
            "15  45079.0             NaN  \n",
            "16  45050.0             NaN  \n",
            "17  45108.0             NaN  \n",
            "18  45139.0  Temporary Site  \n",
            "19      6.0             NaN  \n"
          ]
        }
      ],
      "source": [
        "# применить метод head\n",
        "\n",
        "print(df.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze-lXxLMhpWv"
      },
      "source": [
        "2.2 Оценка данных с помощью метода info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bjhngmaLiGM-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 161 entries, 0 to 160\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   START_DATE    161 non-null    object \n",
            " 1   END_DATE      161 non-null    object \n",
            " 2   CATEGORY*     161 non-null    object \n",
            " 3   START         161 non-null    object \n",
            " 4   STOP          161 non-null    object \n",
            " 5   MILES         161 non-null    float64\n",
            " 6   PURPOSEroute  84 non-null     object \n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 8.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# выполнит метод info\n",
        "\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06PDq9DAiMAY"
      },
      "source": [
        "2.3 Оценка данных с помощью метода describe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cTVFwzO1jQfN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              MILES\n",
            "count    161.000000\n",
            "mean   37766.519255\n",
            "std    16614.925558\n",
            "min        0.800000\n",
            "25%    44931.000000\n",
            "50%    45008.000000\n",
            "75%    45081.000000\n",
            "max    45177.000000\n"
          ]
        }
      ],
      "source": [
        "# оцените числовые столбцы с помощью describe\n",
        "\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOZUrZGuiGqc"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Итого, я познакомился с ключевыми методами для первичного анализа данных. Метод head() позволяет быстро просмотреть начало датасета и убедиться, что данные загружены корректно. Метод info() даёт общую информацию о структуре DataFrame: количество строк и столбцов, типы данных и наличие пропущенных значений. Метод describe() предоставляет основные статистические характеристики числовых признаков — среднее, стандартное отклонение, минимум, максимум, квартили**\n",
        "\n",
        "\n",
        " ---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTbo0IGDiHxn"
      },
      "source": [
        " 2.4 Оценка названий столбцов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9NEyi2Odik3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['START_DATE', 'END_DATE', 'CATEGORY*', 'START', 'STOP', 'MILES',\n",
            "       'PURPOSEroute'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Вывести на экран названия столбцов с помощью df.columns. Выявить проблемы с названиями, если они есть. При необходимости переименовать столбцы. Если проблемы не обнаружены также дать пояснения.\n",
        "\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проблем не возникло, но лучше переименовать названия столбцов CATEGORY* -> CATEGORY, PURPOSEroute -> PURPOSE_ROUTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QSJBLl4qjjP8"
      },
      "outputs": [],
      "source": [
        "# переименование при необходимости\n",
        "\n",
        "df = df.rename(columns={\n",
        "    'CATEGORY*': 'CATEGORY',\n",
        "    'PURPOSEroute': 'PURPOSE_ROUTE'\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0tLQcyrjnA_"
      },
      "source": [
        "### 3. Проверка пропусков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xuTz-Avjj9AW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START_DATE        0\n",
            "END_DATE          0\n",
            "CATEGORY          0\n",
            "START             0\n",
            "STOP              0\n",
            "MILES             0\n",
            "PURPOSE_ROUTE    77\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Проверить данные на наличие пропусков и устранить их, если они есть (пропуски необходимо либо удалить, либо заменить каким-то значением).\n",
        "\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START_DATE       0\n",
            "END_DATE         0\n",
            "CATEGORY         0\n",
            "START            0\n",
            "STOP             0\n",
            "MILES            0\n",
            "PURPOSE_ROUTE    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df['PURPOSE_ROUTE'] = df['PURPOSE_ROUTE'].fillna('Unknown')\n",
        "\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efZ7vgSVkPQH"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Я решил не удалять строки с пропущенными данными, а обозначить их как \"неизвестно\", тк удаление строк приведет к потере почти половины данных (77 строк из 161), что может сильно исказить анализ данных и снизить статистическую значимость.**\n",
        "\n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkyrXXHikEXk"
      },
      "source": [
        "### 4. Проверка дубликатов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImqHvr3okIQ6"
      },
      "source": [
        "#### Проверка явных дубликатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qu1oh-e5lDZ1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество дубликатов: 2\n",
            "\n",
            "          START_DATE         END_DATE  CATEGORY        START  STOP    MILES  \\\n",
            "159  7.26.2016 22:31  7.26.2016 22:39  Business  Morrisville  Cary  45048.0   \n",
            "160  7.26.2016 22:31  7.26.2016 22:39  Business  Morrisville  Cary  45048.0   \n",
            "\n",
            "      PURPOSE_ROUTE  \n",
            "159  Meal/Entertain  \n",
            "160  Meal/Entertain  \n"
          ]
        }
      ],
      "source": [
        "print(\"Количество дубликатов:\", df.duplicated().sum())\n",
        "\n",
        "print()\n",
        "print(df[df.duplicated()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ntArgvChkK26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Строк до удаления: 161\n",
            "Строк после удаления: 159\n"
          ]
        }
      ],
      "source": [
        "# удалите дубликаты, если они есть\n",
        "\n",
        "print(\"Строк до удаления:\", len(df))\n",
        "df = df.drop_duplicates()\n",
        "print(\"Строк после удаления:\", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeHTMcOmkLSw"
      },
      "source": [
        "#### Проверка неявных дубликатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-uOPKHlVlGo8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== START_DATE ===\n",
            " ['01.10.2016 19:12', '01.11.2016 13:32', '01.12.2016 12:33', '02.01.2016 12:10', '02.04.2016 9:37', '02.07.2016 18:03', '02.07.2016 20:22', '02.09.2016 20:24', '02.11.2016 20:36', '02.12.2016 11:14', '02.12.2016 15:33', '03.04.2016 19:16', '03.05.2016 14:08', '03.05.2016 17:23', '04.12.2016 13:42', '05.03.2016 22:20', '05.04.2016 21:30', '05.06.2016 16:45', '05.06.2016 17:18', '05.06.2016 5:47', '05.11.2016 21:47', '06.01.2016 13:10', '06.05.2016 18:05', '06.06.2016 21:08', '06.11.2016 17:34', '07.06.2016 0:33', '07.06.2016 23:46', '07.07.2016 10:27', '07.09.2016 10:15', '07.12.2016 23:47', '08.01.2016 15:40', '08.01.2016 17:23', '08.02.2016 11:51', '08.05.2016 19:17', '08.06.2016 9:31', '08.07.2016 20:15', '08.08.2016 23:28', '08.10.2016 18:49', '08.10.2016 19:47', '1.13.2016 15:00', '1.29.2016 21:21', '1.30.2016 18:09', '10.15.2016 22:28', '10.16.2016 0:01', '10.16.2016 15:10', '10.16.2016 21:34', '10.17.2016 18:31', '10.17.2016 19:08', '10.19.2016 13:45', '10.20.2016 20:44', '10.22.2016 0:54', '10.23.2016 21:10', '10.24.2016 16:34', '10.25.2016 15:04', '10.25.2016 20:54', '10.27.2016 19:20', '10.27.2016 21:26', '10.29.2016 17:13', '10.30.2016 10:11', '10.30.2016 10:51', '10.30.2016 12:24', '10.30.2016 12:58', '10.30.2016 13:24', '10.30.2016 9:07', '10.31.2016 18:47', '11.02.2016 17:34', '11.02.2016 17:53', '11.03.2016 22:46', '11.04.2016 18:14', '11.04.2016 21:04', '11.05.2016 19:20', '11.05.2016 8:34', '11.06.2016 10:50', '11.06.2016 16:27', '11.10.2016 14:57', '11.11.2016 21:08', '11.12.2016 10:55', '11.12.2016 15:14', '11.13.2016 13:14', '11.18.2016 21:23', '11.19.2016 21:14', '11.22.2016 21:02', '11.26.2016 17:36', '11.27.2016 18:55', '11.30.2016 12:43', '12.01.2016 20:36', '12.02.2016 13:07', '12.02.2016 22:59', '12.03.2016 20:31', '12.04.2016 20:23', '12.09.2016 13:15', '12.10.2016 22:09', '12.12.2016 14:26', '12.12.2016 20:48', '12.14.2016 20:24', '2.14.2016 14:46', '2.16.2016 10:31', '2.16.2016 11:32', '2.16.2016 12:39', '2.16.2016 13:43', '2.16.2016 16:34', '2.16.2016 17:17', '2.17.2016 15:17', '2.17.2016 15:33', '2.22.2016 21:54', '2.29.2016 12:36', '3.13.2016 20:07', '3.17.2016 17:20', '3.18.2016 18:24', '3.18.2016 7:15', '3.18.2016 8:35', '3.19.2016 17:17', '3.19.2016 19:33', '3.19.2016 9:10', '3.20.2016 17:08', '3.20.2016 18:45', '3.20.2016 7:37', '3.21.2016 10:21', '3.21.2016 18:59', '3.22.2016 12:06', '3.22.2016 6:17', '3.29.2016 18:20', '3.29.2016 20:29', '4.16.2016 15:10', '4.28.2016 22:10', '5.14.2016 23:01', '5.18.2016 13:00', '5.20.2016 15:43', '5.22.2016 18:46', '5.27.2016 20:47', '5.28.2016 14:35', '6.15.2016 16:37', '6.16.2016 14:42', '6.18.2016 0:29', '6.25.2016 10:50', '6.25.2016 11:53', '6.25.2016 23:19', '6.27.2016 11:30', '6.27.2016 12:22', '6.27.2016 13:56', '6.28.2016 0:48', '6.29.2016 10:22', '7.13.2016 13:25', '7.13.2016 13:42', '7.14.2016 16:39', '7.16.2016 19:42', '7.18.2016 10:54', '7.18.2016 18:32', '7.18.2016 21:11', '7.19.2016 17:50', '7.21.2016 19:30', '7.22.2016 11:11', '7.22.2016 15:49', '7.23.2016 14:48', '7.23.2016 15:50', '7.25.2016 11:04', '7.26.2016 22:31', '7.27.2016 21:34', '7.28.2016 0:04']\n",
            "\n",
            "=== END_DATE ===\n",
            " ['01.10.2016 19:32', '01.11.2016 13:46', '01.12.2016 12:49', '02.01.2016 12:43', '02.04.2016 10:09', '02.07.2016 18:17', '02.07.2016 20:40', '02.09.2016 20:40', '02.11.2016 20:51', '02.12.2016 11:35', '02.12.2016 16:06', '03.04.2016 19:25', '03.05.2016 14:18', '03.05.2016 17:34', '04.12.2016 14:01', '05.03.2016 22:28', '05.04.2016 21:36', '05.06.2016 16:59', '05.06.2016 17:44', '05.06.2016 6:02', '05.11.2016 22:04', '06.01.2016 13:39', '06.05.2016 18:14', '06.06.2016 21:37', '06.11.2016 17:39', '07.06.2016 0:53', '07.06.2016 23:59', '07.07.2016 10:33', '07.09.2016 10:33', '08.01.2016 15:47', '08.01.2016 17:55', '08.02.2016 12:15', '08.05.2016 19:27', '08.06.2016 9:53', '08.07.2016 20:23', '08.08.2016 23:37', '08.10.2016 18:50', '08.10.2016 20:02', '1.13.2016 15:28', '1.29.2016 21:40', '1.30.2016 18:24', '10.15.2016 22:48', '10.16.2016 0:14', '10.16.2016 15:19', '10.16.2016 21:41', '10.17.2016 18:45', '10.17.2016 19:25', '10.19.2016 13:56', '10.20.2016 21:37', '10.22.2016 1:09', '10.23.2016 21:25', '10.24.2016 16:41', '10.25.2016 15:11', '10.25.2016 21:03', '10.27.2016 19:35', '10.27.2016 21:48', '10.29.2016 19:19', '10.30.2016 10:09', '10.30.2016 10:38', '10.30.2016 11:21', '10.30.2016 12:35', '10.30.2016 13:18', '10.30.2016 14:37', '10.31.2016 19:16', '11.02.2016 17:49', '11.02.2016 18:00', '11.03.2016 22:58', '11.04.2016 18:21', '11.04.2016 21:20', '11.05.2016 19:28', '11.05.2016 8:43', '11.06.2016 11:04', '11.06.2016 17:28', '11.10.2016 15:07', '11.11.2016 21:18', '11.12.2016 11:25', '11.12.2016 15:21', '11.13.2016 13:18', '11.18.2016 21:34', '11.19.2016 21:35', '11.22.2016 21:14', '11.26.2016 17:56', '11.27.2016 19:09', '11.30.2016 12:53', '12.01.2016 20:46', '12.02.2016 13:22', '12.02.2016 23:07', '12.03.2016 20:41', '12.04.2016 20:34', '12.09.2016 13:43', '12.10.2016 22:21', '12.12.2016 14:39', '12.12.2016 20:57', '12.14.2016 20:40', '2.14.2016 15:03', '2.16.2016 10:41', '2.16.2016 12:02', '2.16.2016 12:42', '2.16.2016 13:55', '2.16.2016 17:10', '2.16.2016 17:26', '2.17.2016 15:22', '2.17.2016 16:17', '2.22.2016 22:09', '2.29.2016 12:48', '3.13.2016 20:28', '3.17.2016 18:02', '3.18.2016 19:08', '3.18.2016 7:21', '3.18.2016 8:43', '3.19.2016 17:32', '3.19.2016 20:39', '3.19.2016 9:25', '3.20.2016 17:34', '3.20.2016 19:06', '3.20.2016 7:48', '3.21.2016 10:26', '3.21.2016 19:15', '3.22.2016 12:24', '3.22.2016 6:43', '3.29.2016 18:39', '3.29.2016 20:44', '4.16.2016 15:26', '4.28.2016 22:28', '5.14.2016 23:05', '5.18.2016 13:02', '5.20.2016 16:12', '5.22.2016 18:53', '5.27.2016 20:53', '5.28.2016 15:04', '6.15.2016 17:02', '6.16.2016 14:46', '6.18.2016 0:51', '6.25.2016 11:18', '6.25.2016 13:21', '6.25.2016 23:26', '6.27.2016 11:42', '6.27.2016 13:02', '6.27.2016 14:05', '6.28.2016 1:05', '6.29.2016 10:38', '7.13.2016 0:11', '7.13.2016 13:39', '7.13.2016 13:54', '7.14.2016 20:05', '7.16.2016 20:35', '7.18.2016 11:15', '7.18.2016 18:47', '7.18.2016 21:19', '7.19.2016 18:08', '7.21.2016 19:39', '7.22.2016 11:25', '7.22.2016 16:22', '7.23.2016 15:12', '7.23.2016 16:10', '7.25.2016 11:33', '7.26.2016 22:39', '7.27.2016 21:57', '7.28.2016 0:09']\n",
            "\n",
            "=== CATEGORY ===\n",
            " ['BUSINESS', 'Business', 'Personal']\n",
            "\n",
            "=== START ===\n",
            " ['Agnew', 'Almond', 'Apex', 'Arabi', 'Arlington', 'Boone', 'Briar Meadow', 'Bryson City', 'Capitol One', 'Chapel Hill', 'Chessington', 'College Avenue', 'Colombo', 'Columbia Heights', 'Galveston', 'Georgian Acres', 'Gulfton', 'Hayesville', 'Lower Garden District', 'Mandeville', 'Marigny', 'Metairie', 'Midtown', 'Morrisville', 'SOMISSPO', 'San Jose', 'Sand Lake Commons', 'Santa Clara', 'Savon Height', 'Sky Lake', 'South', 'South Berkeley']\n",
            "\n",
            "=== STOP ===\n",
            " ['Agnew', 'Alief', 'Almond', 'Apex', 'Asheville', 'Banner Elk', 'Berkeley', 'Bryson City', 'Cary', 'Central', 'Colombo', 'Cory', 'Downtown', 'Eagle Rock', 'East Harlem', 'Emeryville', 'French Quarter', 'Greater Greenspoint', 'Holly Springs', 'Houston', 'Hudson Square', 'Kalorama Triangle', 'Katunayaka', 'Kenner', 'Kilarney Woods', 'Lakeview', 'Mandeville', 'Mcvan', 'Metairie', 'Midtown', 'Midtown East', 'Midtown West', 'Morrisville', 'New Orleans', 'Nugegoda', 'Parkway', 'Port Bolivar', 'Raleigh', 'Renaissance', 'Sand Lake Commons', 'Santa Clara', 'Sharpstown', 'Sky Lake', 'Southside', 'Southwest Berkeley', 'Storyville', 'Tenderloin', 'The Drag', 'Topton', 'University District', 'Washington', 'Washington Avenue', 'Whitebridge']\n",
            "\n",
            "=== PURPOSE_ROUTE ===\n",
            " ['Customer Visit', 'MEETING', 'Meal/Entertain', 'Meeting', 'Moving', 'Temporary Site', 'Unknown']\n"
          ]
        }
      ],
      "source": [
        "print(\"=== START_DATE ===\\n\", sorted(df['START_DATE'].unique()))\n",
        "print(\"\\n=== END_DATE ===\\n\", sorted(df['END_DATE'].unique()))\n",
        "print(\"\\n=== CATEGORY ===\\n\", sorted(df['CATEGORY'].unique()))\n",
        "print(\"\\n=== START ===\\n\", sorted(df['START'].unique()))\n",
        "print(\"\\n=== STOP ===\\n\", sorted(df['STOP'].unique()))\n",
        "print(\"\\n=== PURPOSE_ROUTE ===\\n\", sorted(df['PURPOSE_ROUTE'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Итого, неявные дубликаты есть в столбцах 'CATEGORY', 'START', 'STOP', 'PURPOSE_ROUTE' (из-за регистра). Поэтому ниже я приведу все значения к одному регистру и на всякий случай уберу лишние пробелы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_columns = ['CATEGORY', 'START', 'STOP', 'PURPOSE_ROUTE']\n",
        "\n",
        "# Применяем очистку к каждому столбцу\n",
        "for col in text_columns:\n",
        "    df[col] = df[col].astype(str).str.strip().str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "89tMFEQ2k_M7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Строк до удаления: 159\n",
            "Строк после удаления: 159\n"
          ]
        }
      ],
      "source": [
        "# удалите дубликаты, если они есть\n",
        "\n",
        "print(\"Строк до удаления:\", len(df))\n",
        "df = df.drop_duplicates()\n",
        "print(\"Строк после удаления:\", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMcnDpOmlKhU"
      },
      "source": [
        "---\n",
        "\n",
        "**Итого, явных дубликатов оказалось 2 и после их удаления количество строк уменьшилось с 161 до 159. После этого я обнаружил, что в некоторых ячейках могут быть одинаковые значения по смыслу, но по-разному написаны, что может привести к допуску неявных дубликатов. Поэтому я унифицировал такие данные. Но, после этого дубликатов обнаружено не было, поэтому после выполнения кода количество строк так и осталось равно 159.**\n",
        "\n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md9GhfYMlbi7"
      },
      "source": [
        "### 5. Провека типов данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lXTroENaluCW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 159 entries, 0 to 158\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   START_DATE     159 non-null    object \n",
            " 1   END_DATE       159 non-null    object \n",
            " 2   CATEGORY       159 non-null    object \n",
            " 3   START          159 non-null    object \n",
            " 4   STOP           159 non-null    object \n",
            " 5   MILES          159 non-null    float64\n",
            " 6   PURPOSE_ROUTE  159 non-null    object \n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 9.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WXhXgu29lop3"
      },
      "outputs": [],
      "source": [
        "# Проверьте типы данных, при необходимости измените типы данных, чтобы они соответствовали действительности.\n",
        "\n",
        "df['START_DATE'] = pd.to_datetime(df['START_DATE'], format='%m.%d.%Y %H:%M')\n",
        "df['END_DATE'] = pd.to_datetime(df['END_DATE'], format='%m.%d.%Y %H:%M')\n",
        "\n",
        "cat_cols = ['CATEGORY', 'PURPOSE_ROUTE']\n",
        "df[cat_cols] = df[cat_cols].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPDBNN4dlx7W"
      },
      "source": [
        "---\n",
        "\n",
        "**Итого: столбцы с датами (START_DATE, END_DATE) переведены в тип datetime64[ns], что позволяет корректно выполнять временные операции (расчёт длительности поездок, извлечение часа или дня недели и т.д.). Категориальные признаки CATEGORY и PURPOSE_ROUTE преобразованы в тип category, поскольку они содержат небольшое число уникальных значений, что снижает потребление памяти и ускоряет обработку без потери информации.**\n",
        "\n",
        "\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzr0SgqlnmHy"
      },
      "source": [
        "### 6. Группировка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_dbwzfmZoS"
      },
      "source": [
        "#### Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyCKTB4DmciW"
      },
      "source": [
        "*` Группировка - CATEGORY  и количество поездок для каждой очки \n",
        "старта (START)`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp8Bl1gumYlI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START     agnew  almond  apex  arabi  arlington  boone  briar meadow  \\\n",
            "CATEGORY                                                               \n",
            "business      4       1    17      1          1      0             1   \n",
            "personal      0       0     0      0          0      1             0   \n",
            "All           4       1    17      1          1      1             1   \n",
            "\n",
            "START     bryson city  capitol one  chapel hill  chessington  college avenue  \\\n",
            "CATEGORY                                                                       \n",
            "business            5            2            2            0               1   \n",
            "personal            0            0            0            1               0   \n",
            "All                 5            2            2            1               1   \n",
            "\n",
            "START     colombo  columbia heights  galveston  georgian acres  gulfton  \\\n",
            "CATEGORY                                                                  \n",
            "business        8                 1          2               1        1   \n",
            "personal        0                 0          0               0        0   \n",
            "All             8                 1          2               1        1   \n",
            "\n",
            "START     hayesville  lower garden district  mandeville  marigny  metairie  \\\n",
            "CATEGORY                                                                     \n",
            "business           1                      1           2        1         4   \n",
            "personal           0                      0           0        0         0   \n",
            "All                1                      1           2        1         4   \n",
            "\n",
            "START     midtown  morrisville  san jose  sand lake commons  santa clara  \\\n",
            "CATEGORY                                                                   \n",
            "business       13           68         2                  0            1   \n",
            "personal        1            6         0                  1            0   \n",
            "All            14           74         2                  1            1   \n",
            "\n",
            "START     savon height  sky lake  somisspo  south  south berkeley  All  \n",
            "CATEGORY                                                                \n",
            "business             2         0         2      2               1  148  \n",
            "personal             0         1         0      0               0   11  \n",
            "All                  2         1         2      2               1  159  \n"
          ]
        }
      ],
      "source": [
        "# выполните группировку согласно варианту\n",
        "\n",
        "grouped = pd.crosstab(\n",
        "    index=df['CATEGORY'],    \n",
        "    columns=df['START'],     \n",
        "    margins=True             \n",
        ")\n",
        "\n",
        "print(grouped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLmhNuq0mms3"
      },
      "source": [
        "**`Для анализа распределения поездок по категориям и точкам старта была построена сводная таблица с использованием pd.crosstab(). В результате получено количество поездок для каждой комбинации категории (CATEGORY) и места начала поездки (START)`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0isGCzEne7a"
      },
      "source": [
        "#### Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE2vLBWbne7a"
      },
      "source": [
        "*`Группировка - CATEGORY  и количество поездок каждого типа (по цели \n",
        "маршрута). Создать датафрейм. Переименовать столбец с количеством в “сountˮ. \n",
        "Отсортировать по убыванию столбца “countˮ`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ttn78Zaene7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    CATEGORY   PURPOSE_ROUTE  count\n",
            "5   business         unknown     67\n",
            "1   business  meal/entertain     34\n",
            "0   business  customer visit     30\n",
            "2   business         meeting     13\n",
            "11  personal         unknown     10\n",
            "4   business  temporary site      4\n",
            "9   personal          moving      1\n",
            "3   business          moving      0\n",
            "7   personal  meal/entertain      0\n",
            "6   personal  customer visit      0\n",
            "8   personal         meeting      0\n",
            "10  personal  temporary site      0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dolbo\\AppData\\Local\\Temp\\ipykernel_11236\\647307302.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  result_df = df.groupby(['CATEGORY', 'PURPOSE_ROUTE']).size().reset_index(name='count')\n"
          ]
        }
      ],
      "source": [
        "# выполните группировку согласно варианту\n",
        "\n",
        "result_df = df.groupby(['CATEGORY', 'PURPOSE_ROUTE']).size().reset_index(name='count')\n",
        "result_df = result_df.sort_values(by='count', ascending=False)\n",
        "\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCyyeAu6ne7a"
      },
      "source": [
        "**`Была выполнена группировка данных по категории поездки (CATEGORY) и её цели (PURPOSE_ROUTE). Для каждой комбинации подсчитано количество поездок. Результат представлен в виде датафрейма с переименованным столбцом количества в \"count\". Данные отсортированы по убыванию частоты встречаемости.`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3fHGp64nhUJ"
      },
      "source": [
        "#### Задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bc4ehyKnhUJ"
      },
      "source": [
        "*`Сводная таблица (pivot_table) - максимальное количество пройденных \n",
        "миль по каждой категории(CATEGORY). Отсортировать по убыванию столбца \n",
        "MILES.`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "siDovPvQnhUJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            MILES\n",
            "CATEGORY         \n",
            "business  45177.0\n",
            "personal  45161.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dolbo\\AppData\\Local\\Temp\\ipykernel_11236\\2245511576.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
            "  pivot_df = pd.pivot_table(\n"
          ]
        }
      ],
      "source": [
        "# выполните сводную таблицу согласно варианту\n",
        "\n",
        "pivot_df = pd.pivot_table(\n",
        "    data=df,\n",
        "    index='CATEGORY',        \n",
        "    values='MILES',          \n",
        "    aggfunc='max'           \n",
        ")\n",
        "\n",
        "pivot_df = pivot_df.sort_values(by='MILES', ascending=False)\n",
        "\n",
        "print(pivot_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-vw8iyUnhUK"
      },
      "source": [
        "**`С помощью сводной таблицы (pd.pivot_table) была определена максимальная величина пройденных миль (MILES) для каждой категории поездок (CATEGORY). Результат отсортирован по убыванию значения MILES.`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOlw74xCniNo"
      },
      "source": [
        "#### Задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tvYwT25niNq"
      },
      "source": [
        "*`Сводная таблица (pivot_table) - средняя количество пройденных миль \n",
        "по каждой цели поездки (PURPOSEroute) - столбцы и каждой категории - строки. \n",
        "Отсортировать по убыванию столбца CATEGORY`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TfJ719g6niNq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PURPOSE_ROUTE  customer visit  meal/entertain       meeting   moving  \\\n",
            "CATEGORY                                                               \n",
            "personal                  NaN             NaN           NaN  44932.0   \n",
            "business         36023.196667    41054.823529  34646.846154      NaN   \n",
            "\n",
            "PURPOSE_ROUTE  temporary site       unknown  \n",
            "CATEGORY                                     \n",
            "personal                  NaN  36035.000000  \n",
            "business              45063.5  36982.219403  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dolbo\\AppData\\Local\\Temp\\ipykernel_11236\\4207110198.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
            "  pivot_df = pd.pivot_table(\n"
          ]
        }
      ],
      "source": [
        "# выполните сводную таблицу согласно варианту\n",
        "\n",
        "pivot_df = pd.pivot_table(\n",
        "    data=df,\n",
        "    index='CATEGORY',        \n",
        "    columns='PURPOSE_ROUTE', \n",
        "    values='MILES',          \n",
        "    aggfunc='mean'           \n",
        ")\n",
        "pivot_df = pivot_df.sort_index(ascending=False)\n",
        "\n",
        "print(pivot_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqJqvk5qniNr"
      },
      "source": [
        "**`Сводная таблица показывает, что деловые поездки (business) в среднем длиннее личных (personal), а наибольшие расстояния связаны с целями вроде «customer visit». Отсутствие данных в некоторых ячейках указывает, что отдельные типы поездок (например, «temporary site») встречаются только в бизнес-категории.`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpnXb6gip3S8"
      },
      "source": [
        "### Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqLa096jM1Z8"
      },
      "source": [
        "\n",
        "**В ходе выполнения работы я познакомился с библиотекой pandas и освоил ключевые этапы предварительной обработки и анализа данных. Я научился: загружать данные из CSV-файлов с учётом разделителя; проверять и корректировать названия столбцов; выявлять и обрабатывать пропуски, явные и неявные дубликаты; преобразовывать типы данных (включая даты и категориальные признаки); использовать методы head(), info(), describe() для разведочного анализа; группировать данные и строить сводные таблицы с помощью groupby() и pivot_table().\n",
        "Эти навыки позволили мне привести сырые данные к чистому и анализируемому виду, а также получить содержательные инсайты о структуре поездок по категориям, целям и пройденным расстояниям.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn3y7og_vjGG"
      },
      "source": [
        "### Дополнительное задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR6WgHXYvlqD"
      },
      "source": [
        "**`Подробная формулировка задания`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG5TGQpevlBq"
      },
      "outputs": [],
      "source": [
        "# код выполнения задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-qpTuhTvon3"
      },
      "source": [
        "***`Подробный вывод по заданию, описание полученных результатов`***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
